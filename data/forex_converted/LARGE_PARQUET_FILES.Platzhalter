# ğŸ“Š Large Forex Parquet Files - Platzhalter

**Directory:** `data/forex_converted/`  
**Large Files (>25MB):**
- `EURUSD-2025-04.parquet` (85MB)
- `EURUSD-2025-05.parquet` (78MB)  
- `EURUSD-2025-06.parquet` (51MB)

## ğŸ“‹ File Description

These files contain processed EUR/USD forex data in Parquet format:

- **EURUSD-2025-04.parquet:** April 2025 EUR/USD tick data (85MB)
- **EURUSD-2025-05.parquet:** May 2025 EUR/USD tick data (78MB)
- **EURUSD-2025-06.parquet:** June 2025 EUR/USD tick data (51MB)

## ğŸ”„ How to Regenerate

To regenerate these files, run:

```bash
# Activate virtual environment
source test_env/bin/activate

# Process forex data
python -m ai_indicator_optimizer.data.dukascopy_connector --month 2025-04
python -m ai_indicator_optimizer.data.dukascopy_connector --month 2025-05
python -m ai_indicator_optimizer.data.dukascopy_connector --month 2025-06

# Or use the main application
python -m ai_indicator_optimizer.main_application --mode data_processing
```

## ğŸ“Š Data Structure

Each Parquet file contains:

```
Columns:
â”œâ”€â”€ timestamp: datetime64[ns]
â”œâ”€â”€ bid: float64
â”œâ”€â”€ ask: float64
â”œâ”€â”€ bid_volume: float64
â”œâ”€â”€ ask_volume: float64
â”œâ”€â”€ mid_price: float64
â””â”€â”€ spread: float64

Typical Size: 50-85MB per month
Rows: ~2-3 million ticks per month
```

## ğŸ¯ Usage

These files are used for:
- **Tick Data Analysis:** High-frequency market analysis
- **OHLCV Generation:** Bar data creation for multiple timeframes
- **AI Training:** Multimodal dataset preparation
- **Backtesting:** Historical strategy validation

## âš ï¸ Note

These are placeholder files. The original Parquet files are too large for GitHub (>25MB limit). Generate locally using the DukascopyConnector.

---

**ğŸ“… Generated:** September 22, 2025  
**ğŸ¯ Status:** Placeholder for 214MB total forex data  
**ğŸ”„ Regeneration:** Run DukascopyConnector for each month