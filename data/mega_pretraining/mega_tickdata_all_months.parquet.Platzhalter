# 📊 Mega Tickdata All Months - Platzhalter

**Original File:** `mega_tickdata_all_months.parquet`  
**Size:** 498MB  
**Type:** Consolidated tick data for all months  

## 📋 File Description

This file contains consolidated EUR/USD tick data from multiple months:

- **Data Period:** April-June 2025 (3 months)
- **Total Ticks:** ~14.4 million professional tick records
- **Data Quality:** Institutional-grade with bid/ask spreads
- **Processing Performance:** 27,273 ticks/second achieved

## 🔄 How to Regenerate

To regenerate this mega dataset:

```bash
# Activate virtual environment
source test_env/bin/activate

# Run mega pretraining data preparation
python -m ai_indicator_optimizer.data.mega_pretraining_data_prep

# Or use the consolidated processor
python scripts/consolidate_tickdata.py --months 2025-04,2025-05,2025-06
```

## 📊 Data Structure

```
Consolidated Tickdata Structure:
├── timestamp: datetime64[ns] - UTC timestamps
├── instrument: string - "EURUSD"
├── bid: float64 - Bid prices (5 decimal precision)
├── ask: float64 - Ask prices (5 decimal precision)
├── bid_volume: float64 - Bid volume
├── ask_volume: float64 - Ask volume
├── mid_price: float64 - Calculated mid price
├── spread: float64 - Bid-ask spread
├── month: int8 - Month identifier (4, 5, 6)
└── processing_batch: int32 - Processing batch ID

Total Rows: ~14,400,075 ticks
File Size: 498MB (compressed Parquet with ZSTD)
```

## 🎯 Usage in AI-Indicator-Optimizer

This mega dataset is used for:

1. **Professional Tickdata Processing:** Investment bank level performance
2. **Multimodal AI Training:** Vision + Text model training data
3. **Strategy Backtesting:** High-quality historical validation
4. **Performance Benchmarking:** System performance validation

## 📈 Processing Performance

When this file was processed:
- **Processing Time:** 8.8 minutes for 14.4M ticks
- **Processing Rate:** 27,273 ticks/second (Investment Bank Level)
- **Hardware Utilization:** 95%+ (RTX 5090 + 32 cores + 182GB RAM)
- **Success Rate:** 100%

## 🔗 Related Files

This mega dataset generates:
- `mega_ohlcv_1m.parquet` (3.8MB) - 1-minute bars
- `mega_ohlcv_5m.parquet` (915KB) - 5-minute bars  
- `mega_ohlcv_15m.parquet` (375KB) - 15-minute bars
- `mega_ohlcv_1h.parquet` (108KB) - 1-hour bars
- `mega_ohlcv_4h.parquet` (34KB) - 4-hour bars
- `mega_ohlcv_1d.parquet` (9.9KB) - Daily bars

## ⚠️ Note

This is a placeholder file. The original 498MB Parquet file contains the complete consolidated tickdata and is too large for GitHub. Generate locally using the mega pretraining data preparation pipeline.

---

**📅 Generated:** September 22, 2025  
**🎯 Status:** Placeholder for 498MB mega tickdata  
**🔄 Regeneration:** Run mega pretraining data prep pipeline  
**🚀 Performance:** 27,273 ticks/second processing achieved